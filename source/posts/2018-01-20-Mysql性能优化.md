---
title: MySQL性能优化
abbrlink: f75280fd
date: 2018-01-20 23:08:55
tags: 数据库
categories: 数据库
---
<!--  -->
<!-- more -->
## MySQL逻辑架构

MySQL的逻辑架构大致分为三层:

![](/images/mysql-0.png)

## 基准测试

sysbench

## 性能剖析

性能定义: 完成某件任务所需要的时间度量, 以响应时间作为性能指标, 吞吐量作为性能优化的副产品.


性能剖析的手段:

- `SHOW STATUS`: 返回一些计数器, 既有基于连接的会话级别计数器, 也有服务器级别全局计数器;
- `SHOW PROLIE`: 默认关闭, 通过`SET PROFILING=1`开启后, 在服务器上执行的所有语句, 都会测量其耗费的时间和其他一些查询执行状态变更相关的数据;
- `慢查询日志`: 默认关闭, 用来记录在MySQL中响应时间超过阀值的语句, 通过`long_query_time`参数设置阀值(默认10s). 另外日志分析工具有`pt-query-digst`和`mysqldumpslow`;
- `Performance Schema`: 以存储引擎的方式实现, 用于收集数据库服务器性能参数;
- `Information Schema`: 提供了访问数据库元数据的方式, 可以`STATISTICS`表查看一些索引信息;
- `EXPLAIN`: 查看一些SQL语句的执行计划.
<!-- more -->
## Schema优化

### 几个简单原则

- 更小的通常更好: 尽量使用可以正确存储数据的最小数据类型但是要确保没有低估需要存储的值的范围;
- 简单就好: 尽量使用简单的数据类型, 比如整型优于字符类型, 字符类型有字符集和校对规则, 因此更加复杂; 使用内建日期类型而不是字符串保存日期和时间, 用整型存储Ip地址而不是字符串.
- 尽量避免NULL：让一个列为可以NULL的会导致耗费很多的存储空间, 尤其是那些预计会建立索引的列, 可NULL的列会导致索引的统计和值比较更加复杂.
- 选择类型的时候, 先确定合适的大类型: 整形/字符串/日期等, 然后在确定具体类型.

### 数值类型

- `TINYINT`,`SMALLINT`,`MEDIUMINT`,`INT`,`BIGINT`分别对应`8`,`16`,`24`,`32`,`64`位存储空间, 以及提供`UNSIGNED`属性, 表示不允许负值;
- `FLOAT\DOUBLE`类型支持单精度浮点运算和双精度浮点运算, 这种计算是近似的, 不精确的, 这是现行计算机架构的通病, 是由底层决定的, 不是MySQL导致的;
- `DECIMAL`类型支持精确的计算, 存储精确的小数. 但是这是有代价的, 这种类型的运算比浮点运算慢, 占用空间更多;
- 推荐使用`BIGINT`来存储精确数字, 比如要精确到`0.0001`, 那么存储数字的时候乘以一万, 而取出数字后再除以一万. 这样可以避免浮点运算的精度问题, 又不用付出`DECIMAL`高昂的代价;
- 注意MySQL的存储类型, 运算类型和客户端显示格式的区别;

### 字符串类型

- `CHAR/VARCHAR`
	- `VARCHAR`变长, 需要1到2个额外的字节记录长度, 存储和检索时会保留末尾的空格;
	- `CHAR`定长, 存储时会删除末尾空格, 采用空格填充以方便比较;
	- 填充和截取空格的行为发生在服务器层, 与存储引擎无关;
	- `CHAR(n)`和`VARCHAR(n)`中的`n`代表的是字符而不是字节;
- `BINARY/VARBINNARY`: 存储的二进制字符串, 填充`BINARY`采用的是零字节`\0`, 检索不会去掉填充值.
- `BLOB/TEXT`:
	- 存储很大的数据时使用这两种类型
	- 当`BLOB/TEXT`太大时, `InnoDB`会使用额外的存储区进行存储, 在行内使用1-4个字节存储指针;
	- 针对`BLOB/TEXT`, 排序和索引只会使用前面的小部分字符

### 日期类型

- `DATETIME`: 保存`1001`年至`9999`年范围的日期, 精度为秒, 存储到格式为`YYYYMMDDHHMMSS`的整数中, 占8字节, 以一种直观的方式显示;
- `TIMESTAMP`: 保存格林尼治标准时间以来的秒数, 只能表示`1970`年至`2038`年, 占4个字节, 按时区显示;

### 其他类型

- `ENUM`:

### 标识列选择

- 确保某一种标识一旦选定了类型, 就在所有关联的表中使用同一类型, 包括`UNSIGNED`这样的属性;
- 在满足值的要求, 并充分考虑到未来扩展性的情况下, 应使用尽可能小的数据类型, 比如存储美国各州的名字(另一张表)的`id`列, 不需要`INT`, `TINYINT`就够了;
- `整数 > ENUM/SET > 字符串`, 整数的性能和扩展性最好, 字符串最糟糕, 占用很多空间, 性能也差的多;
- 对于`MD5()`, `SHA1()`, `UUID()`这种产生随机字符串的函数要特别注意, 这些函数生成的值会导致插入和查询变得很慢, 而对于写非常多的大表, 使用"伪随机"值可以消除热点;
- 存储`UUID`值, 要去掉’-‘号, 或者用`UNHEX()`函数转换`UUID`为`16`字节的数字, 存储在`BINATY(16)`中, 检索时再通过`HEX()`格式化成十六进制形式;

### 应该避免的情况

- 太多的列: 因为MySQL会在工作时, 从存储引擎层和服务器层之间通过行缓冲格式拷贝数据, 然后从行缓冲将编码过的列在服务器端解码成各个列, 转换的代价依赖于列的数量。`MyISAM`定长行结构与服务器层的行结构不需要转换, 而`InnoDB`和`MyISAM`的变长行结构总是需要转换;
- 太多关联: MySQL限制每个关联操作最多只有61张表. 避免`实体-属性-值(EAV)`设计模式. 为追求查询速度和并发性, 单个查询最好是12个表以内关联.
- 注意防止过度使用枚举: 一个好的建议是使用整数关联到字典表或查找表, 找到具体指;
- 变相的枚举: 避免在应该使用`ENUM`的情况下使用`SET`, 比如存储是`Y`还是`N`的列。如果不会同时出现`YN`，就不需要`SET`类型;
- 在避免使用`NULL`的原则下不要走极端, 使用特殊常数可能造成代码的`BUG`.

### 范式与反范式

三大范式这里不做叙述了, 总结一下范式和反范式的区别:

- 反范式会存储一些冗余数据, 所以通常查询会更快, 另一方面为了保持数据的一致性, 更新操作通常比范式化的数据表慢;
- 范式化意味着没有冗余数据, 所以一般不需要`DISTINCT`和`GROUP BY`语句;

在数据库`Schema`优化中, 大部分的工作都在衡量范式化和反范式上, 实际情况通常需要两者的结合.

### 技巧

- 缓存表/汇总表: 在满足检索需求时, 经常使用这种技巧. 需要权衡的问题是实时维护还是定期重建(一般来讲这是更好的选择);
- 计数表: 在维护计数器的时候, 有时考虑到并发的影响, 可以将计数器切分到不同槽上, 再汇总起来;
- 物化试图: 需要借助外部工具.
- 加快`ALTER TABLE`的速度: 对于大表来讲`ALTER TABLE`的性能是一个大问题, 有两种方法可以加快`ALTER TABLE`的速度:
	- 通过`ALTER COLUMN`操作来改变列的默认值, 这不会导致表的重建;
	- 采用替换`.frm`文件的方式: 创建一张结构相同的空表, 修改表结构, 锁定原表, 替换`.frm`文件, 解锁原表.
- 快速创建`MyISAM`索引: 先引用索引, 载入数据, 在重启索引. 这会索引的构建延迟到数据完全载入后, 这个时候可以使用排序创建索引;

## 索引优化

### B-Tree索引

__一定要先看`B-Tree`和`B+Tree`数据结构和磁盘的存取原理.__

简单说一下:

- `B-Tree`可以利用磁盘存储的局部性原理和磁盘预读, 减少读取磁盘的次数;
- 一个`B-Tree`节点一般对应"系统页"的整数倍, 连续的地址, 使用的时候加载到内存中(页分裂/碎片等会导致"随机I/O"); 而从磁盘读取索引节点, 一般是"随机I/O"(可以重建索引优化为"顺序I/O"). `MyISAM`索引的数据行读取是"随机I/O". (可能理解的有问题...)
- `B+Tree`根节点内存常驻, 内部节点只保存键值, 数据保存在叶子节点上, 相邻的叶子节点之间有指针相连, 能够提高区间查询的效率;
- 因为`B-Tree`按顺序存储索引键值, 所以`ORDER BY`和`GROUP BY`十分高效;

#### InnoDB

InnoDB引擎的主键索引, 如下图(这里索引是整数值):

![](/images/mysql-3.png)

可以看到`InnoDB`的主索引结构有一个明显的特点: 叶节点包含了完整的数据记录, 这也就是说`InnoDB`表数据文件本身就是主索引. 这种索引称为`簇族索引`, 每个叶子节点都包含了主键值, 事务ID, 用于事务和`MVCC`的回滚指针以及剩余的列, 如果主键是一个列前缀索引, `InnoDB`也会包含完整的主键列和剩余列.

`InnoDB`表有且仅能有一个"簇族索引", 如果没有显示指定主键, 存储引擎会从唯一非空索引中选择一个替代, 如果无法选择, 则生成一个隐藏字段作为主键, 6个字节的长整型.

由于"簇族索引"的特性, 所以一个优化建议是: 对于`InnoDB`表, 最好采用数字类型, 且具有自增规律的列作为主键. 如果是主键具有自增规律, 那么就可以通过避免插入的过程中`B+Tree`子树的重建, 来减少开销, 另外针对磁盘存储, 还可能有效地减少由于"页分裂"产生的碎片.

再来看看`InnoDB`的二级索引(这里的索引是字符串):

![](/images/mysql-4.png)

对于`InnoDB`的二级索引, 叶子节点里保存的不再是完整数据, 而是主键值, 所以`InnoDB`的二级索引需要两次索引查找. 这里不存"地址指针"的原因是: 这种策略减少了当行移动或者数据页分裂时导致的二级索引维护工作(存储"主键"不需要变动).

知道了`InnoDB`的二级索引原理, 我们也就能理解为什么建议`InnoDB`主键索引采用数值类型而不是字符串了, 因为字符串会在二级索引上占据更多的存储空间.

#### MyISAM

`MyISAM`的索引结构如下:

![](/images/mysql-1.png)

和`InnoDB`的不同之处在于: `MyISAM`索引的叶子节点中存储的数据的物理地址, 这一点对于主键索引和二级索引没有区别. 两者之间的唯一区别是主键索引要求必须非空唯一.

另外`MyISAM`还采用一种"压缩索引"("前缀索引")的技术: 先保存索引块的第一个值, 然后将后面的值和第一个值进行比较, 得到相同的前缀的字节数和剩下不同的后缀部分. 例如: 假设索引的第一个值是"perform", 第二个值是"performmance"的话, 那么第二个值前缀压缩后存储的是类似"7,ance"这样的形式.

前缀压缩技术能够大幅度的减少磁盘存储空间, 以及降低`I/O`压力, 但是在查找索引块的时候, 只能退化到顺序查找, 无法利用二分查找.

### 最左前缀原理

在进行索引优化前, 必须先弄明白什么样的查询会使用索引, 这和`B-Tree`索引限制有关.

假设我们有如下数据表`People`:

```sql
CREATE TABLE `People` (
  `last_name` varchar(45) NOT NULL,
  `first_name` varchar(45) NOT NULL,
  `dob` date NOT NULL,
  `gender` enum('m', 'f') NOT NULL,
  KEY(`last_name`,`first_name`,`dob`)
)ENGINE=InnoDB DEFAULT CHARSET=latin1;
```

索引由`last_name`,`first_name`和`dob`组成. 考虑如下几种情况:

- 全值匹配<br>
	指的是和索引中的所有列进行匹配. 例如查找姓名为`Cuba Allen`, 出生于`1960-01-10`的人;

- 匹配最左前缀值<br>
	可以只使用索引的最左侧列, 例如查找所有姓氏为`Allen`的人;

- 匹配范围值<br>
	也可以只是用列的前缀部分, 例如查找所有姓氏以`J`开头的人;

- 精确匹配某一列并范围匹配另一列<br>
	也可以匹配姓氏为`Allen`, 名字以`K`开头的人, 即第一列全匹配, 第二列范围匹配;

也有些情况不会使用索引:

- 查询条件中含有函数或表达式<br>
	例如使用`left`函数查找姓氏前4个字符为`Alle`的人;

- `like`关键字<br>
	如果使用以`like %llen`形式匹配姓氏, 则不会使用索引, 如果通配符`%`不出现在开头, 则可以使用索引;

- 不符合最左前缀原则<br>
	例如跳过第一列姓氏匹配名字, 或者范围匹配不在最右侧;

### 高性能索引策略

先前介绍了索引的原理和相关特性, 现在我们来看看怎么建立高效地选择和使用索引.

#### 索引选择性

索引的选择性: 不重复的索引值(也称为"基数")/数据表的记录总数. 选择性越高的索引查询效率越高, 因为高的选择性在查找时能过滤更多的行. 唯一索引的选择性为`1`, 性能最好.

定义好了索引选择性, 就不得不提"前缀索引": 通过只取字符串(通常是字符串)的合适前缀来建立索引, 从而缩小索引的体积. 另外MySQL强制规定在`BLOB/TEXT`或更长的`VARCHAR`类型上只能建立前缀索引.

在选择多长的前缀这个问题上, 我们可以通过索引选择性来找到答案: 先计算完整列的索引选择性, 然后慢慢增加前缀, 逼近完整列的索引选择性. 这个过程可以利用`COUNT`和`LEFT`函数.

另外在多列索引的选择问题上, 也可以参考索引选择性(但不是绝对).

另外前缀索引也有缺点: 无法用来排序和分组, 也无法用来作为"覆盖索引".

#### 多列索引

在选择索引上, 我们经常面临两个问题:

- 是使用多个单独的一列作为索引, 还是建立一个多列的索引?
- 如果使用多列索引, 那么这些列之间以什么样的顺序定义呢?

我们先来解决第一个问题, 在多个单独的列上定以索引大部分情况下并不能提高MySQL性能.

在MySQL5.0后, 引入了一种叫"索引合并"的策略, 在查询是能够同时使用多个单独的索引进行扫描, 并将结果合并. 这个算法有三个变种: `OR`联合, `AND`相交以及组合前两种情况的相交和联合. 不过这会耗费大量的CPU和内存资源在算法的缓存, 排序和合并操作上, 而且查询优化器不会把这部分的损耗计算在内.

所以一种更健壮的索引设计是多列索引, 这就要求我们结合用到的查询, 定义好合适的索引列顺序.

当你定义好一个索引列的顺序后, 索引首先会按照最左列排序, 在后续的查询语句要求遵循"最左前缀原理", 以正确的使用索引.

对于如何选择索引列顺序的一个经验法则是: 索引列选择性高的放在前面. 这在优化`WHERE`条件查询时, 无疑是最快的, 然而实际情况中还需要考虑具体值的分布, 以及排序, 分组和范围查找等情况.

#### 按主键顺序插入行

最好避免随机的(不连续且值的分布范围十分广)簇族索引.

如果是按主键顺序插入的话, 那么存储引擎就会顺序的添加到当前索引节点的后面, 当一页写满("填充因子": 减少在数据移动或追加的时候的页分裂可能), 就自动开辟一个新的页.

如果插入的是随机值, 那么每次插入新的记录, 都需要寻找合适的位置---通常是已有位置的中间. 如果写入的目标页已经写入磁盘, 还需要重新读取, 由于是乱序的会造成"随机I/O", 页分裂操作和磁盘碎片.

#### 覆盖索引

如果一个索引包含所有要查询的列的值, 就称为"覆盖索引". 覆盖索引可以使存储引擎不需要从数据行获取数据, 而是直接使用扫面索引获取数据.

这对I/O密集型的应用十分有帮助, 因为索引更小, 更容易放在内存中, 而且`B-Tree`索引是顺序存储的, 至少在单个页上是顺序I/O. 另外对于`InnoDB`的二级索引, 省去了第二次查找主键索引的消耗.

另外有一个小技巧叫"延迟关联", 它可以在需要所有列的情况下, 充分利用覆盖索引.

#### 使用索引排序

MySQL有两种排序方式: 排序操作, 按索引顺序扫描排序.

使用索引做排序和使用索引查找一样遵循"最左前缀原理"(列的顺序相同), 而且多个`ORDER BY`的排序方向必须一致(都是正序或倒序), 如果关联多张表, 那么`ORDER BY`子句引用的字段都必须是第一张表.

有一种情况可以不满足"最左前缀原理": 那就是一个前导列被赋予了常量值, 例如索引(birth, last_name):

```sql
select * from people where birth='1996-10-14' order by last_name desc;
```

#### 重复索引

MySQL允许在相同的列上创建多个索引, 大多数情况下, 这些索引都是多余的, 会浪费存储空间, 并且插入记录时维护这些索引需要耗费时间. 应该避免创建重复索引, 发现后也要立即移除.

不过也有些情况下, 考虑到性能需求需要创建重复索引, 扩展原有的索引会导致其变大, 影响其他使用该索引的查询的性能.

### 哈希索引

哈希索引给予哈希表实现, 只有在精确匹配所有列的情况下才能使用, MySQL中只有`Memory`存储引擎支持哈希索引.

哈希索引只存储哈希值和行地址, 不过这一点影响不大, 因为在内存中的读取速度不是问题.

哈希索引在满足查找速度的时候, 牺牲了许多`B-Tree`索引的特性, 比如: 不支持部分索引列匹配, 排序, 范围匹配和比较计算等.

`InnoDB`有个特性"自适应哈希索引(Adaptive Hash Index, AHI)": `InnoDB`会注意某些`索引列`用得非常频繁时, 它会为`缓冲池`中的`B-Tree`树`页`建立哈希索引. 据官方文档显示, 在启用`AHI`后, 读取和写入速度会提升两倍, 辅助索引(存储了主键值)的连接操作性能可以提升五倍. AHI是一种数据库`自优化`手段, 无需人为干涉.

另外, 利用哈希函数和触发器, 我们可以创建"自定义哈希索引", 其思想是: 使用哈希值替换那些十分长的索引列, 实质还是`B-Tree`索引. 例如有索引列(url_crc):

```sql
select * from url where url="http://www.mysql.com" and url_crc=CRC32("http://www.mysql.com")
```

在这里, 优化器会使用这个选择性很高而且体积小的`url_crc`索引列完成查找, 即使发生哈希冲突, 通过简单的几次键值比较就可以找到记录. 使用触发器维护哈希值:

```sql
DELIMETER //

CREATE TRIGGER pseudohash_crc_ins BEFORE INSERT ON pseudohash FOR EACH ROW BEGIN
SET NEW.crc_url=crc32(NEW.url);
END;
//

CREATE TRIGGER pseudohash_crc_upd BEFORE UPDATE ON pseudohash FOR EACH ROW BEGIN
SET NEW.crc_url=crc32(NEW.url);
END;
//

DELEMETER ;
```


### 全文索引

## 查询优化

查询优化, 索引优化和库表结构优化需要齐头并进, 一个不落. 客户端发送一条`SQL`给MySQL服务器的整个查询流程:

![](/images/mysql-5.jpg)

### 为何查询如此慢?

在进行查询优化之前, 我们先要弄明白一个查询任务是由哪些子任务构成的, 哪些子任务运行的速度很慢?

在这里没有给出完整的列表, 不过可以按查询的生命周期来进行分析: 客户端, 服务器, 解析, 生成执行计划, 执行, 并返回结果给客户端. 逐步分析问题出在哪, 优化哪部分能得到大幅度的性能提升.

查询任务的大部分时间会消耗在网络, CPU计算, 生成统计信息和执行计划, 锁等待等操作, 尤其是为了检索数据发起的对存储引擎的调用, 这些调用需要在内存操作, CPU操作以及内存不足引起的I/O操作消耗时间.

*阿姆达尔定律: 对于一个占总响应时间不超过5%的查询进行优化, 无论如何努力, 收益也不会超过5%

### 优化数据访问

查询效率低下往往是因为访问的数据太多了. 对于低效查询, 我们可以通过下面两点发现问题所在:

- 是否向数据库请求了不需要的数据: 会给MySQL带来额外的负担, 增加网络开销, 浪费服务器CPU和内存资源. 常见的几种错误案例:
	- 查询不需要的行: 这种情况往往发生在应用程序编程的时候, 例如: 只取数据库结果集前面部分, 然后关闭结果集.
	- 获取不需要的列: 我们应该对`SELECT *`持审视态度, 是否真的需要全部列? 这一点在多表关联的时候尤为严重, 它会返回所有表的所有列.
	- 重复查询相同的数据: 这种情况, 我们可以在应用程序将数据缓存起来, 减少数据库查询.

- MySQL是否在扫描额外的记录: 直白来讲就是MySQL需要扫描多少数据, 才能返回我们需要的数据.<br>
	一个理想的状态是: `扫描的行数=返回的行数=需要的行数`.<br>
	为了评估MySQL查询开销, 我们需要理解几个概念: `全表扫描`,`索引扫描`,`范围查询`,`唯一索引访问`和`常数引用`. 这里列的这些, 可以通过`EXPLAIN`中的`type`看到, 速度由慢到快.<br>
	如果发现MySQL扫描了大量的额外数据, 通常可以采用下面几种技巧:
	- 索引: 索引可以让MySQL访问合适的数据;
	- 覆盖索引: 可以不用回表查询数据行;
	- 优化库表结构: 例如汇总表;
	- 重构查询: 让MySQL优化器以更优的方式执行这个查询;

### 嵌套循环关联

MySQL没有哈希关联, 合并关联, 所有关联都是"嵌套循环关联". 如果要写出高效的多表关联查询, 就必须先弄明白什么是"嵌套循环关联", 如下图:

![](/images/mysql-6.jpg)

嵌套循环关联: MySQL先在一个表中循环取出单条数据, 然后再嵌套循环到下一个表中寻找匹配的行, 依次下去, 直到知道到所有表中匹配的行.

既然理解了MySQL的嵌套循环关联, 也就明白为什么提倡使用"小结果集来驱动大结果集, 对被驱动的表的关联列建立索引"(因为外层循环中结果集大的话, 意味着嵌套循环的次数多, 即更多的磁盘I/O).

MySQL查询优化器最重要的一部分工作就是关联查询优化, 能在多种不同的关联顺序中, 找到成本比较低的关联顺序("贪婪"搜索). 这一点上, 优化器大多数情况都能做得很好, 如果人为不能很好的分析各种关联顺序, 可以将工作交给优化器完成.

关于嵌套循环关联, 还有几个相关的问题:

- 对于排序, 如果所有`ORDER BY`都发生在驱动表, 那么MySQL能在驱动表查找过程中就排好序, 否则, 需要在返回的结果集(临时表)上排序.
- 对于`UNION`操作, MySQL无法将限制条件(`LIMIT`)从"外层"下推到内层, 它会将结果集合并成临时表, 然后在返回前`N`条. 一个优化建议是, 分别对单独查询加上`LIMIT`限制. (还有一点就是从临时表中取出的数据的顺序是不一定的, 必要的话, 还需要全局的排序).
- `GROUP BY`和`DISITNC`通常需要在临时表上进行操作.
- 关联子查询

### 查询优化器

MySQL查询优化器使用了非常多的优化策略和算法, 来生成一个较优的执行计划:

- 重新定义表的关联顺序: 数据表的关联顺序并不总是查询指定的顺序;
- 将外连接转换成内连接: `WHERE`条件和库表结构可能会让外连接变为内连接;
- 使用等价变换规则: 使用等价变换来简化并规范表达式;
- 优化`COUNT()`,`MIN()`,`MAX()`: `B-Tree`索引可以直接找到最小最大值, 而MyISAM存储引擎有记录数据表总行数.
- 预估并转化为常数表达式;
- 覆盖索引扫描;
- 子查询优化
- 提前终止查询
- 等值传播
- 列表`IN()`比较: 先对列表值排序, 再二分查找.(而`OR`是简单顺序查找).

另外, MySQL也提供了丰富的查询优化器提示(`hint`), 例如: `HIGH_PRIORITY`,`USE INDEX`,`FOR UPDATE`...

### 优化特定类型的查询

#### COUNT()

关于`COUNT`这个话题, 互联网上有一大堆的信息, 但大多不够准确. 在这里总结一下:

- 首先, `COUNT(*)`并不会扩展到所有列, 它只是统计行数(结果集/数据表).

- 然后对于`MyISAM`引擎, 因为它有记录数据表的行数, 所以`COUNT(*)`会很快. 例如:

	```sql
	select * from count(*) from tb;
	```
 	但是一旦使用了`WHERE`条件(并且没有优化掉), 就会退化到全扫描(可能是全表扫描或索引扫描). 假设我们有主键`i`, 索引`val`以及字段`bar`:

 	```sql
 	select count(*) from tb where i < 10000;  /* 索引扫描 */
 	select count(*) from tb where val < 10000; /* 全表扫描*/
 	```
	在都退化到索引扫描的时候,　例如：
	```sql
	select count(*) from tb where i < 10000; /* 最快 */
	select count(i) from tb where i < 10000; /* 和count(*)等价 */
	select count(val) from tb where i < 10000; /* 较慢 */
	```
	`COUNT(*)`会快于`COUNT(COL)`是因为前者只需要统计行数, 而后者要回表查找数据行(除非`COUNT(COL)`使用了覆盖索引, 即`count(i)`). 那么可不可以认为在`InnoDB`引擎中, 如果都走的是簇族索引的话, 是不是`COUNT(*)`和`COUNT(COL)`就没有区别了呢? (还没有去实验...)

- 另外, 有个特殊情况就是[MySQL下count(*)比count(id)慢的原因？](https://www.zhihu.com/question/50171821). <br>
	`MyISAM`存储引擎下两个SQL语句, 这个表的主键为`id`, `status`列有个索引:
	```sql
	select count(*) from dr_keywords where status=0;  /* [1]. 0.8秒 */
	select count(id) from dr_keywords where status=0;  /* [2]. 0.5秒 */
	```
	以及数据分布情况如下:
	```code
	+--------+----------+
	| status | count(*) |
	+--------+----------+
	|      0 |  1060349 |
	|      1 |     2995 |
	|      9 |      236 |
	+--------+----------+
	```
	这里分析的原因是: [1]SQL语句走的是`status`索引扫描, 而语句[2]被优化器优化为全表扫描.<br>
	先不谈为什么优化器会将语句[2]优化为全表扫描, 单说索引扫描为什么会慢.<br>
	大部分情况下, 所以扫描会块

- 在5.7版本中，`InnoDB`实现了新的`handler`的`records`接口函数，当你需要表上的精确记录个数时，会直接调用该函数进行计算,

所以总的来说, 大多数情况下`COUNT(*)`会不慢于`COUNT(COL)`, 但是也有例外情况. 实际还可能和索引使用情况, 数据分布情况以及数据库版本和存储引擎相关.

#### LIMIT()

在业务中需要进行"分页"操作时, 我们经常使用数据库层的`OFFSET`和`LIMIT`实现, 并在`ORDER BY`的列上加上索引.

一个令人头疼的问题是: 在偏移量非常大的时候. 例如`LIMIT 10000,20`这样的查询, 会造成MySQL查询`10020`条记录然后返回最后`20`条, 造成前面`10000`条记录被丢弃.

这种问题的优化策略是: 限制分页数量, 另一个是优化查询在大偏移量时的性能.

优化这类查询最简单的一个做法是, 尽量使用覆盖索引, 可以避免MySQL回表查询数据行. 如果无法做到覆盖索引, 也可以使用前面介绍的"延迟关联"的技巧. 例如:

```sql
select film.film_id, film.description
from sakila.film
inner join (
	select film_id from sakila.film
	order by title limit 50,5
) as lim using(film_id);
```

另外一种思路是尽可能的减少MySQL扫描的记录数, 先确定范围, 然后取N条. 例如:

```sql
select film_id, description from sakila.film where position between 50 and 54 order by position;
```

如果上层应用程序能够记录上一次取数据的位置, 这种范围查找的方式, 在无论偏移量多大的情况下, 都能取得良好的性能.

"分页"带来的另一个问题是, 需要知道一共能查到多少数据, 以方便应用程序计算"总页数".

一个常用的技巧是在`LIMIT`语句中加上`SQL_CALC_FOUND_ROWS`提示（`hint`), 这样做可以获得去掉`LIMIT`以后满足条件的行数, 因此可以作为分页的总数. 看起来, MySQL做了一些非常高深的优化, 像是通过某种方法预测了总行数. 但实际上MySQL只有在扫描了所有满足条件的行，然后再抛弃掉不需要的行，而不是在满足`LIMIT`的行数后就终止扫描. 所以该提示的代价非常高, 在数据量大的时候性能很差.

一个更好的设计方案是将具体的页面换成“下一页”按钮, 假设每页显示`20`条记录, 那么我们每次查询都是用`LIMIT`返回`21`条记录并只显示`20`条, 如果第`21`条存在, 那么我们就显示“下一页”按钮, 否则就说明没有更多的数据, 也就无需显示“下一页”按钮了.

还有一种做法, 那就是在应用程序层做"分页", 例如, 我们一次加载`1000`条数据, 缓存下来, 以后的分页都从这个缓存中取. 如果结果集小于`1000`, 就可以显示所有的页面链接, 否则, 增加一个发现大于`1000`条数据提示.

#### IN()




#### UNION


## Resources

`>>> `[Mysql5.6 Performance_schema 深入浅出](http://keithlan.github.io/2015/07/17/22_performance_schema/)<br>
`>>> `[MySQL索引背后的数据结构及算法原理](http://blog.codinglabs.org/articles/theory-of-mysql-index.html)<br>
`>>> `[如果有人问你数据库的原理, 叫他看这篇文章](http://blog.jobbole.com/100349/)<br>

