---
title: 理解 asyncio
abbrlink: cc755aee
date: 2018-01-30 23:26:24
tags:
    - Python
    - 异步编程
categories: Python
---

在本篇文章, 我试图从三个方面: 协程, Python对协程的语法支持以及`asyncio`库, 来理解事件驱动的异步编程.

<!-- more -->

## 概念

我们先给协程一个正式的定义: **“协程是为非抢占式多任务产生子程序的计算机程序组件, 协程允许不同入口点在不同位置暂停或开始执行程序”**(来自维基百科).

### 协程和线程

从协程的定义, 我们可以很好的区分协程和线程行为上的区别: 协程由应用程序提供机制提供, 属于"协作式多任务"; 而线程一般由操作系统提供, CPU负责调度, 属于"抢占式多任务". 

尽管协程和线程都能用来"并发"编程, 但需要考虑到使用多线程会有以下几个问题:

- 线程在计算和资源消耗的角度是较为昂贵的;
- 在使用线程进行"并发"编程时, 需要考虑访问共享资源时, "竞态条件"和"锁机制"带来的复杂性和安全性问题;
- 由于`GIL`的存在, Python的多线程无法发挥多核CPU的计算能力, 只有在遇到I/O阻塞的时, 才会释放`GIL`锁.
- 既然Python的多线程更适用于"I/O"密集的场景, 那么在这种情形下, 使用协程替代线程应该能得到更好的性能.

### 事件循环

在继续学习协程之前, 我们弄明白什么是事件循环?

比如大部分的网络服务器框架, 诸如`werkzeug`,`Django`等实现的`HTTPServer`, 在底层都是使用I/O多路复用机制处理客户端连接的:

```python
def loop():
    while not QUIT:
        events = selector.select(events_to_listen, timeout)
        for event in events:
            process_request(events)
```

这里的`loop`就相当于是一个事件循环, 它等待操作系统的事件通知, 并执行相应请求处理函数(回调函数).

这里的`select`会阻塞直到请求的到来(或超时), 其实`select`底层的实现也是一个事件循环, 轮询监听的文件描述符`fd`, 在`fd`数据准备好时, 返回文件描述符, 不过我们先不关心这些. 尽管这里会发生阻塞, 但是其好处是在有大量并发连接的情况下, 使用IO多路复用不会造成: 阻塞在单个IO下, 而导致无法处理其他请求. 它会在有任何连接准备好的时候, 返回文件描述符.

(PS: 不知道我这里理解的事件循环有没有问题...)

事件循环: "是一种等待程序分配事件或消息的编程架构"(来自wiki). 简单来讲, 事件循环是一种循环机制, 监听哪些事件发生了, 并关心事件发生时做什么处理, 让你可以在"A发生时, 执行B". 

然而, 要想设计健壮的WEB 服务框架, 单单这点还不够, 目前请求的处理都发生在单个线程中, 像`socket.recv()`、访问数据库以及读写文件等都会发生阻塞, 导致阻塞整个事件循环. 所以, 一般的WEB服务器还提供了多线程/多进程的选项, 能够以线程或进程的方式处理请求. 另外一种思路是, 将事件循环放在一个单独的子线程里, 事件的处理都放在主线程中.

事件循环机制是理解异步编程的核心之一, 另一个核心就是协程.

### 协程和回调

回到事件驱动的主题上来, 当事件发生时, 事件循环机制需要找到相应的处理函数, 尽管WEB框架的处理函数一般就一个, 然后再做分派. 但是更一般的, 像`JS`中的事件就很多, 比如`OnClick`事件, 往往需要将回调函数绑定到相应的事件上, 这样才能在事件发生时执行对应的回调函数. 这就是异步机制.

当回调发生时, 我们可能会碰到下面这种情况:

```python
def stage_1(response_1):  # 回调函数1
    request_2 = step_1(reponse_1) # 对响应处理, 并生成新的请求2

    def stage_2(response_2):
        request_3 = step_2(reponse_2)

        def stage_3(response_3):
            step_3(reponse_3)

        api_call_3(request_3, stage_3) # 调用新的API函数3, 注册回调函数3
    api_call_2(request_2, stage_2)  # 调用新的API函数2, 注册回调函数2

api_call_1(request_1, stage_1)  # 调用API函数1, 注册回调函数1
```

- 代码结构不清晰: 同步的代码结构是从上往下, 而嵌套回调的结构会导致`callback hell`.
- 上下文状态丢失: 执行下一个回调的时候, 无法获取上一步的`request_1`的信息. 如果需要那个值, 必须通过参数传递, 或者闭包实现.
- 异常处理: 当`api_call_2`发生异常时, 无法在`stage_1`函数中捕获, 因为是`api_call_2`异步调用. `JS`针对这个问题的解决方案是, 注册两个回调函数, 其中有一个用作异常处理, 这样以来就变得更加复杂了.

同样的代码逻辑, 我们可以用另外一种方式来重构:

```python
@asyncio.coroutine
def three_stages(request_1):
    response_1 = yield from api_call_1(request_1) # 第一步

    request_2 = step(response_1) # 第二步
    reponse_2 = yield from api_call_2(request_2)

    reqeust_3 = step(response_2) # 第三步
    response_3 = yield from api_call_3(request_3)

loop.create_task(three_stages(request_1)) # 必须显示调用
```

使用协程不会存在上面那些问题, 因为整个任务执行是顺序的, 并且在一个上下文中, 如果需要捕捉异常的话, 可以使用`try/catch`将`yield from`语句包裹起来.

## Python语法

### yield和yield from

PEP 342 中定义了协程的底层架构, 并在Python2.5中实现了. 至此`yield`成为表达式, 能够暂停执行产生值.

PEP 342 中为生成器API添加了`send()`方法, 可以将数据给暂停的的生成器, 发送的值成为`yield`表达式的值. 这样以来, 生成器就可以作为协程使用了.

PEP 380 为Python3.3引入了`yield from`语法, 以便生成器能够更好地作为协程使用. 在生成器`gen`中调用`yield from subgen()`时, `subgen`会获得控制权, 把产生的值返回给调用方, 即调用方可以直接控制`subgen`. 与此同时, `gen`会挂起, 等待`subgen`返回值(终止). `yield from`可以把复杂的生成器重构为小型的嵌套生成器. 例如:

```python
def subgen():
    while True:
        x = yield 'subgen'

def gen():
    yield from 'AB'
    yield from range(1, 3)
    yield from subgen()
```

`yield from x`表达式对`x`所做的第一件事就是, 调用`iter(x)`, 从中获得迭代器. 

到现在为止, `yield`和`yield from`定义的生成器完全可以作为协程的实现. 仔细一点话, 我们可以发现两者的细微区别:

- 生成器更注重保存状态和产生值;
- 协程强调协同控制程序流, 是数据的消费者. (尽管使用生成器定义的协程也会`yield`产生值)

### async和await

现在有个问题是, 在调用`yield from gen_or_cor()`时, 我们无法确定遍历的是生成器还是协程. 

`asyncio.coroutine`和`types.coroutine`两个装饰器的作用就是: 为消除语法上的歧义. 前者是`asyncio`库的实现, 后者是Python3.5新加入的语言实现, 它会给函数的`__code__.co_flags`添加`CO_ITERABLE_COROUTINE`标识. 

随后Yury Selivanov提交的 "PEP 492---Coroutines with async and await syntax", 在 Python3.5 中得以实现, 新加了两个关键字`async`和`await`. 使用`async def`定义的函数称为"原生协程", 它会设置`CO_COROUTINE`标识. 

到现在为止, 协程和生成器很明确的区分开来了, 另外还有两个标识:

- `CO_COROUTINE`: 标识的是原生协程, 使用`async def`定义;
- `CO_ITERABLE_COROUTINE`: 基于迭代器的协程, 使用`types.coroutine`装饰.

在定义了协程之后, PEP 492 引入了`await`来调用协程, 它只能在`async def`协程函数内部使用:

```python
async def read_data(db):
    data = await db.fetch('SELECT ...')
    ...
```

`await`的用法和`yield from`相似, 暂停`read_data`协程的执行, 直到`db.fetch`完成并返回结果数据.

实际上, `await`内部使用`yield from`实现, 不过它对参数进行了一些额外的验证, 接受一个`awaitable`对象:

- 原生协程. `collections.abc.Coroutine`继承自`Awaitable`, 自然没有问题;
- 基于迭代器的协程, 因为`inspect.isawaitable`内部会识别`CO_ITERABLE_COROUTINE`标识.
- 实现了`__await__`方法(必须返回一个迭代器)的对象, 即`collections.abc.Awaitable`.

我们再来看看这个讨论[《为什么只有基于生成器的协程可以真正的暂停执行并强制性返回给事件循环？》]().

我的理解是真正暂停执行并让步, 将控制权交给事件循环的地方一定发生在`yield`处. 而`await/yield from`都没有交出控制权, 它们会进入到里层的协程, 直到碰到一个`yield`, 又或者是一个实现`__await__`方法的`awaitable`, 这个方法返回的也是一个迭代器.
而原生协程的语法是不允许使用`yield`的, 所以就会有上面那种说法.

不过在实际使用中, 我们使用`await asyncio.sleep(1)`这些包装过的协程函数就OK了, 框架会帮我们处理底层的逻辑.

<hr>

除了协程函数外, PEP 492 还提出了`async for`和`async with`的用法:

**异步上下文管理器和"async with"**

异步上下文管理器指的是在`enter`和`exit`方法处能够暂停执行的上下文管理器.

为了实现这样的功能, 需要加入两个新的`magic method`: `__aenter__`和`__aexit__`. 这两个方法都要返回一个`awaitable`对象.

```python
class AsyncContextManager: # 定义一个上下文管理器
    async def __aenter__(self):
        await log("entering context...")

    async def __aexit__(self, exc_type, exc, tb):
        await log("exiting context...")

async def commit(session, data):  # 实现一个数据库事务管理器
    async with session.transaction():
        await session.update(data)
```

和常规的`with`表达式一样, 可以在一个`async with`表达式中指定多个上下文管理器.

如果向`async with`表达式传入的上下文管理器中没有`__aenter__`和`__aexit__`方法, 这将引起一个错误. 如果在`async def`函数外面使用`async with`，将引起一个`SyntaxError`.

**异步迭代器和"async for"**

一个异步可迭代对象(`asynchronous iterable`)能够在迭代过程中调用异步代码, 而异步迭代器就是能够在`next`方法中调用异步代码. 为了支持异步迭代:

1. 一个对象必须实现`__aiter__`方法, 该方法返回一个异步迭代器(`asynchronous iterator`)对象; 
2. 一个异步迭代器对象必须实现`__anext__`方法，该方法返回一个`awaitable`对象;
3. 为了停止迭代, `__anext__`必须抛出一个`StopAsyncIteration`异常.

```python
class AsyncIterable:  ## 定义一个异步迭代器
    def __aiter__(self):
        return self

    async def __anext__(self):
        data = await self.fetch_data()
        if data:
            return data
        else:
            raise StopAsyncIteration

    async def fetch_data(self):
        ...

async def cor():  # 使用异步迭代器
    async for data in AsyncInterable():
        await process_data(data)
```


把一个没有`__aiter__`方法的迭代对象传递给`async for`将引起`TypeError`. 

和`async with`, `await`一样, 在`async def`函数外部使用`async for`将引起一个`SyntaxError`.

和常规的`for`表达式一样, `async for`也有一个可选的`else`分支.

和正常的生成器抛出`StopIteration`异常告知停止迭代一样, 异步迭代器抛出`StopAsyncIteration`告知外围代码迭代结束.

另外在 "PEP 497--Change StopIteration handling inside generators" 中规定, 所有协程中抛出的`StopIteration`异常, 都被包装在`RuntimeError`中.

<hr>

在 PEP 525--Asynchronous Generators 中提出的异步生成器, 在Python3.6中实现了. 在这之前`async def`内部不允许出现`yield`表达式, 而在 Python3.6 中, 使用`yield`表达式可以定义一个异步生成器. 文档中提出: 经过测试, 异步生成器的性能是异步迭代器的2倍.

文档中给出了一个"每次迭代延迟给定秒数并打印数字"的例子:

```python
class Ticker:  # 异步迭代器版本
    def __init__(self, delay, to):
        self.delay = delay
        self.i = 0
        self.to = to

    def __aiter__(self):
        return self

    async def __anext__(self):
        i = self.i
        if i >= self.to:
            raise StopAsyncIteration
        self.i += 1
        if i:
            await asyncio.sleep(self.delay)
        return i

async def ticker(delay, to): # 异步生成器版本
    for i in range(to):
        yield i
        await asyncio.sleep(delay)
```

异步生成器也实现了`__aiter__`和`__anext__`方法. 在异步生成器里面使用`return`语句将引起`SyntaxError`.

## 出租车运营仿真

到这里, 我们已经大致了解了异步编程的一些概念性问题和Python对协程的语法支持. 在真正接触`asyncio`库之前, 我们从一个出租车运营仿真程序(参考"流畅的Python"的离散仿真)开始, 想想怎么实现一个基于事件的异步编程框架.

假设有几辆出租车, 每辆车会拉几个乘客, 然后回家. 出租车首先驶离车库, 四处徘徊, 寻找乘客; 拉到乘客后, 行程开始; 行程结束, 乘客下车, 继续四处徘徊...

开始动手之前, 我们先想想, 都需要实现些什么?

1. 我们可以协程的方式模拟出租车的生命周期, 这一步应该不难, 利用`async/await`等可以实现阻塞调用时让步. 
2. 有N辆出租车, 如果不用线程实现并发, 那么我们需要一个事件循环, 来驱动协程执行.
3. 实现一个`sleep`函数, 模拟出租车耗时的阻塞操作, 这个函数必须是一个`generator-based coroutine`, 因为需要`yield`让步.

```python
import random
import asyncio
import time
import heapq


@asyncio.coroutine
def sleep(seconds):
    now = time.time()
    wait_until = now + seconds
    actual = yield wait_until  # 让步, 并产出下次唤醒的时间
    return actual - now  # 返回实际等待了多长时间


async def taxi_coro(ident, trips, delay=0):
    print("taxt {ident}: waiting {delay} seconds before leave garage...".
          format(ident=ident, delay=delay))
    detal = await sleep(delay)  # 每辆车延迟delay秒出发
    print("taxi {ident} leave from garage after {detal}".
          format(ident=ident, detal=int(detal)))
    for i in range(trips):
        print("taxi {ident} hover around... ".format(ident=ident))
        detal = await sleep(random.randint(0, 10))
        print("taxi {ident} pick up passenger afer {detal}".format(ident=ident, detal=int(detal)))
        detal = await sleep(random.randint(0, 10))
        print("taxi {ident} drop off passenger afer {detal}".format(ident=ident, detal=int(detal)))

    print("taxi {ident} going to home...".format(ident=ident))
    detal = await sleep(random.randint(0, 10))
    print("taxi {ident} has arrived at home afer {detal}!".format(ident=ident, detal=int(detal)))


class Task():

    def __init__(self, wait_until, coro):
        self.waiting_until = wait_until
        self.coro = coro

    def __eq__(self, other):
        return self.waiting_until == other.waiting_until

    def __lt__(self, other):
        return self.waiting_until < other.waiting_until


class EventLoop:

    def __init__(self, *coros):
        self._new = coros
        self._waiting = []

    def run_until_complete(self):

        for coro in self._new:
            wait_until = coro.send(None)  # 协程预激
            heapq.heappush(self._waiting, Task(wait_until, coro))  # Task加入优先队列

        while self._waiting:

            now = time.time()

            task = heapq.heappop(self._waiting)  # 获取最近需要执行的task

            if now < task.waiting_until:  # 还没到task的执行时间
                detal = task.waiting_until - now  # 还需要等待时间
                time.sleep(detal)  # 直接阻塞事件循环
            try:
                now = time.time()
                wait_until = task.coro.send(now)
                heapq.heappush(self._waiting, Task(wait_until, task.coro))
            except StopIteration as e:
                pass


def main():
    loop = EventLoop(taxi_coro('A', 4), taxi_coro('B', 3, 3), taxi_coro('C', 2, 4))
    now = time.time()
    loop.run_until_complete()
    print("Total elapsed time is {}".format(time.time - now))


if __name__ == '__main__':
    main()
```

下面输出结果:
```bash
taxt A: waiting 0 seconds before leave garage...
taxt B: waiting 3 seconds before leave garage...
taxt C: waiting 4 seconds before leave garage...
taxi A leave from garage after 0
taxi A hover around... 
taxi B leave from garage after 3
taxi B hover around... 
taxi C leave from garage after 4
taxi C hover around... 
taxi C pick up passenger afer 2
taxi A pick up passenger afer 7
taxi A drop off passenger afer 1
taxi A hover around... 
taxi B pick up passenger afer 7
taxi C drop off passenger afer 8
taxi C hover around... 
taxi C pick up passenger afer 0
taxi A pick up passenger afer 7
taxi B drop off passenger afer 8
taxi B hover around... 
taxi C drop off passenger afer 8
taxi C going to home...
taxi A drop off passenger afer 9
taxi A hover around... 
taxi B pick up passenger afer 10
taxi A pick up passenger afer 5
taxi C has arrived at home, total elapsed 30!
taxi B drop off passenger afer 4
taxi B hover around... 
taxi A drop off passenger afer 6
taxi A hover around... 
taxi A pick up passenger afer 5
taxi A drop off passenger afer 1
taxi A going to home...
taxi B pick up passenger afer 10
taxi A has arrived at home, total elapsed 43!
taxi B drop off passenger afer 7
taxi B going to home...
taxi B has arrived at home, total elapsed 50!
Total elapsed time is 50  # 总耗时等于耗时最长的那辆的行程时间
```

从输出结果我们可以发现, 总的耗时时长和耗时最长的出租车的行驶时长相当. 在这个例子里面, 使用了`sleep`产出一个唤醒时间并作出让步, 来模拟异步的阻塞调用. 然而实际应用中这些阻塞调用, 往往涉及I/O, 网络等, 不可能产生一个唤醒时间给事件循环, 这是就需要引入一个概念"Future"(期物), 能够在任务完成时...

## asyncio

`asyncio`是Python 3.4 引入的异步I/O框架(PEP 3156), 提供了使用协程编写单线程并发代码、通过sockets和其他方式进行多路I/O访问、运行网络客户端和服务端以及其他相关原语的基础设施. 正如文档中提出的, 提供的组件详细列表如下:

- 一个包含各种特定系统实现的模块化事件循环(event loop);
- 传输和协议抽象(类似于Twisted);
- 对TCP、UDP、SSL、子进程管道(subprogress pipes)、延时调用以及其他的具体支持(有些可能是系统相关的);
- 模仿concurrent.futures模块但适于事件循环(event loop)使用的Future类;
- 基于yield from(PEP 380)的协程和任务，可以让你用顺序的方式编写并发代码;
- 可以中止的Future和协程;
- 模仿threading模块中的同步原语，可以用在单线程内的协程之间;
- 当你不得不去使用一个将产生阻塞I/O的调用时，有接口可以把这个事件转移到线程池(threadpool).

下面是官方文档中给出的一个例子:

```python
import asyncio

async def compute(x, y):
    print("Compute %s + %s ..." % (x, y))
    await asyncio.sleep(1.0)
    return x + y

async def print_sum(x, y):
    result = await compute(x, y)
    print("%s + %s = %s" % (x, y, result))

loop = asyncio.get_event_loop()
loop.run_until_complete(print_sum(1, 2))
loop.close()
```
上面代码的执行流程如下:

![](/images/tulip_coro.png)

执行过程概述如下:

- 获取当前的事件循环
- 加入

未完待续...

### Coroutine, Future, Task

### Event Loop [Policy]

### Tansport, Protocol



## References

`>>> ` [PEP 255 -- Simple Generators](https://www.python.org/dev/peps/pep-255/)<br>
`>>> ` [PEP 342 -- Coroutines via Enhanced Generators](https://www.python.org/dev/peps/pep-342/)<br>
`>>> ` [PEP 380 -- Syntax for Delegating to a Subgenerator](https://www.python.org/dev/peps/pep-380/)<br>
`>>> ` [PEP 492 -- Coroutines with async and await syntax](https://www.python.org/dev/peps/pep-0492/)<br>
`>>> ` [PEP 3156 -- Asynchronous IO Support Rebooted: the "asyncio" Module](https://www.python.org/dev/peps/pep-3156/)<br>
`>>> ` [Tulip: Async I/O for Python 3](https://www.youtube.com/watch?v=1coLC-MUCJc)<br>
`>>> ` [How the heck does async/await work in Python 3.5?](https://snarky.ca/how-the-heck-does-async-await-work-in-python-3-5/)<br>
`>>> ` [A Web Crawler With asyncio Coroutines](http://www.aosabook.org/en/500L/a-web-crawler-with-asyncio-coroutines.html)<br>
`>>> ` [Python3 asyncio官方文档中文版](https://www.kancloud.cn/kindjeff/asyncio-zh/217023)<br>
`>>> ` [异步的魔法 — asyncio 源码剖析](http://blog.dreamfever.me/the-magic-of-asyncio-1/)