---
title: Redis数据结构与应用
abbrlink: 85682d75
date: 2018-01-27 21:39:01
tags:
  - Redis
  - 数据库
categories: 数据库
---


`Redis`可以存储键与5种不同数据结构类型之间的映射, 这五种数据结构类型分别为: `STRING`,`LIST`,`SET`,`ZSET`和`HASH`.

## 字符串

`Redis`没有采用C语言传统的字符串表示(以空字符结尾的字符数组), 而是自己构建了一种名为"简单动态字符串"(simple dynamic string, SDS)的抽象结构来表示字符串.

C字符串只会作为字符串字面量, 用在一些无须对字符串值作修改的地方, 如打印日志.

```c
redisLog(REDIS_WARNING,"Redis is now ready to exit, bye bye...");
```
<!-- more -->
而在键值存储的时候, `Redis`会使用`SDS`来表示字符串, 值的大小不能超过`512MB`, 其中可以存储以下三种类型值:

- 字节串(byte string)
- 整数
- 浮点数

`Redis`的字符串有几个特性:

- `SDS`结构会保存字符串长度信息, 所以`STRLEN`命令的时间复杂度为`O(1)`;
- `SDS`采用内存预分配和惰性内存释放策略, 来优化减少内存重分配次数;
- 二进制安全: 由于`Redis`不采用空字符作为字符串的结尾标志, 而是记录字符串长度, 所以可以用来保存一系列的二进制数据;
- 虽然`SDS`的字符串是二进制安全的, 但它仍然遵循C字符串以空字符结尾的惯例, 所以可以重用一些C函数来操作字符串.

**应用**

- 计数器或ID生成器
- 将数据打包成位, 需要数据具有连续性质. 优点是存储空间少, 使用位运算速度快. 例如: `Bitemap`, 定长数据存储.
- 分布式锁

**Redis分布式锁**

实现一个`Redis`分布式锁, 需要注意几点:

- Q: 获取的锁需要一个过期时间, 避免在客户端持有锁的途中宕机而导致锁得不到释放.<br>
    A: `Redis`可以很容易地给键添加`Expire`过期时间.

- Q: 获取锁和设置锁的过期时间必须是原子的, 否则客户端依旧可能在中间过程宕机.<br>
    A: `SET`命令, 可以设置过期时间, 并保证原子性.

- Q: 设置锁的过期时间, 设置多久? 过短的话, 锁会在持有阶段被错误的释放掉, 不安全的访问共享资源; 过长的话, 会导致其他客户端长时间无法正常工作.<br>
    A: 可选的做法是`fencing token`机制. 客户端在成功获取锁时, `Redis`服务器会返回锁和一个单调递增的数字. 如果锁已经失效, 且被其他客户端获取的话, 那么失效的客户端在使用`fencing token`访问共享资源时就会失败(因为有了一个更大的值). <br>
    然而关于生成`fencing token`和资源服务器结构如何处理`fencing token`又是另外一个难点了. 
    另外一种做法是资源服务器实现一个`Check-and-Set`的原子机制来拒绝延迟请求, 不保证请求的有序(因为没有递增的`fencing token`, 使用无序的`identifier`), 但是保证处理的互斥.

- Q: 释放锁, 需要一个随机值`identifier`, 保证客户端释放的是自己持有的锁?<br>
    A: 这里使用`uuid`生成一个随机字符串作为`identifier`.

- Q: 释放锁时, 必须保证检查`identifier`和释放锁是原子的, 锁可能在检查和释放的中间过程中, 被过期释放掉, 导致客户端释放了其他客户端持有的锁.<br>
    A: 一种做法是使用`Redis`的"事务"; 另一种做法使用`Lua`脚本.

- Q: 还有一个就是单节点`Redis`无法保证锁的高可用, 需要采用`Redis`"复制", 而`Redis`的主从复制是异步的, 在故障转移的过程中会丧失锁的安全性.<br>
    A: 采用分布式锁算法`RedLock`, 基于`N`个完全独立的`Redis`节点. 然而`RedLock`是构建在不安全的系统模型之上, 它对系统的计记时假设(`timing assumption`)有着比较强的依赖.

这里有一个简单的`Redis`实现分布式锁实现:

```python
import time
import uuid
import threading
import redis


conn = redis.Redis()


def acquire_lock(conn, lockname, timeout=10):
    identifier = str(uuid.uuid4())

    end = time.time() + timeout

    while time.time() < end:
        if conn.set(name="lock:" + lockname, value=identifier, nx=True, px=30000):
            print("acquire_lock...")
            return identifier
        time.sleep(1)
    return False


def release_lock(conn, lockname, identifier):
    if not lockname:
        return False
    lockname = "lock:" + lockname
    while True:
        try:
            pipeline = conn.pipeline(True)
            pipeline.watch(lockname)
            if pipeline.get(lockname) == identifier.encode('utf-8'):
                pipeline.multi()
                pipeline.delete(lockname)
                pipeline.execute()
                print("release_lock...")
                return True
            pipeline.unwatch()
            break
        except redis.exceptions.WatchError as e:
            raise e


class Resource:

    def __init__(self):
        self.identifier = ""
        self.value = 0
        self.mutex = threading.Lock()

    def check_and_set(self, identifier, value):
        with self.mutex:
            if self.identifier == identifier:
                self.value = value


if __name__ == "__main__":
    resource = Resource()
    thread_nums = 5
    threads = []

    def incr():
        identifier = acquire_lock(conn, 'test')
        if identifier:
            resource.identifier = identifier
            for i in range(100):
                value = resource.value + 1
                resource.check_and_set(identifier, value)
            release_lock(conn, 'test', identifier)

    for i in range(thread_nums):
        thread = threading.Thread(target=incr)
        threads.append(thread)

    for thread in threads:
        thread.start()
    for thread in threads:
        thread.join()

    print(resource.value)
```

## 列表

列表的底层是双向链表实现的, 并且通过几个属性保存了链表的头部, 尾部以及长度信息, 所以一些操作, 例如: `LLEN`, `LPOP`和`RPOP`都是`O(1)`的时间复杂度.

`Redis`的列表允许用户从两端推入或弹出元素, 以及各种常见的列表操作. 利用列表的特性, 我们可以实现许多实用的功能, 例如:

- 消息队列(通知类, 延迟更新类)
- 自动补全最近联系人
- 时间轴(很容易截断)

**自动补全**

下面是一个保存最近100名联系人的"自动补全"实现的例子:

```python
import redis


conn = redis.Redis()


def add_update_contacts(conn, user, contact):
    ac_list = 'recent:' + user
    pipe = conn.pipeline(True)
    pipe.lrem(ac_list, contact)
    pipe.lpush(ac_list, contact)
    pipe.ltrim(ac_list, 0, 99)
    pipe.execute()


def fetch_autocomplete_list(conn, user, prefix):
    candidates = conn.lrange('recent:' + user, 0, -1)
    suggestions = []

    for candidate in candidates:
        if candidate.lower().decode('utf8').startswith(prefix):
            suggestions.append(candidate)

    return suggestions


if __name__ == "__main__":
    add_update_contacts(conn, 'user', 'zhongshangwu')
    print(fetch_autocomplete_list(conn, 'user', 'zh'))
```

## 集合

`Redis`集合以无序的方式存储各个不相同的元素, 用户可以快速的进行各种集合操作, 比如检测某个元素是否存在, 以及实现交集, 并集, 差集等.

集合的特性可以应用在社交网络的关注列表上, 可以非常方便的实现如共同关注、共同喜好、二度好友等功能. 不过社交网站数据一般十分庞大, 采用这种方案往往是不切实际的.

## 有序集合

使用`Redis`开发应用程序组件的一个强大数据结构就是有序集合. 和散列存储着键与值之间的映射类似, 有序集合提供了分值的处理命令, 以及根据分值大小有序地获取或扫描成员和分值的命令.

有序集合的底层实现是散列和跳跃表. 跳跃表按分值从小到大的顺序保存了所有元素, 每个跳跃表节点代表一个集合元素, `object`属性指向了元素的成员, 而`double`类型的`score`属性则保存成员的分值. 通过一个持有跳跃表节点的结构, 有序集合能够很好的进行遍历, 取某一分值范围的元素. 另外使用一个字典保存了成员和分值的映射, 键指向元素成员, 而值则保存了元素的分值, 所以能够以`O(1)`时间复杂度的查找给定成员的分值, 例如`ZSCORE`命令. 需要注意的是使用散列和跳跃表来保存集合元素不会产生重复的成员或分值, 也不会浪费额外的内存.

**应用**

- 延迟任务队列
- 排行榜

**延迟任务优先队列**

这里采用多个队列区分优先级, 有序集合存储延迟任务, 并把时间戳作为分值.

```python
import json
import time
import uuid
import threading
import redis
from redis_lock import acquire_lock, release_lock


conn = redis.Redis()
QUIT = False


def execute_delay(conn, queue, *args, priority=0, delay=0, **kwargs):
    identifier = str(uuid.uuid4())
    if delay > 0:
        conn.zadd('delayed:',
                  json.dumps((identifier, queue, priority, args, kwargs)),
                  time.time() + delay)
    else:
        conn.rpush('queue:' + queue + ':%d' % priority, json.dumps((args, kwargs)))
    return identifier


def worker_watch_delayed(conn):

    while not QUIT:
        item = conn.zrange('delayed:', 0, 0, withscores=True)
        if not item or item[0][1] > time.time():
            time.sleep(1)
            continue

        item = item[0][0]
        identifier, queue, priority, args, kwargs = json.loads(item)

        lock = acquire_lock(conn, identifier)
        if not lock:
            continue
        if conn.zrem('delayed:', item):
            conn.rpush('queue:' + queue + ':%d' % priority, json.dumps((args, kwargs)))

        release_lock(conn, identifier, lock)


def worker_watch_queue(conn, queue, callback):
    if not callback:
        return

    while not QUIT:
        queues = conn.keys('queue:' + queue + ':*')
        queues = sorted(queues, key=lambda x: x.decode('utf8').split(':')[-1])
        if queues:
            item = conn.blpop(queues, 10)
            if not item:
                continue

            args, kwargs = json.loads(item[1])
            callback(*args, **kwargs)


if __name__ == "__main__":

    def producer_0():
        count = 0
        while True:
            count += 1
            execute_delay(conn, 'echo', 'producer_0', priority=0, msg=count)
            time.sleep(4)

    def producer_0_delay():
        count = 0
        while True:
            count += 1
            execute_delay(conn, 'echo', 'producer_0_delay', priority=1, delay=4, msg=count)
            time.sleep(2)

    def producer_1():
        count = 0
        while True:
            count += 1
            execute_delay(conn, 'echo', 'producer_1', priority=2, msg=count)
            time.sleep(1)

    def callback(producer, msg):
        print('%s' % producer + ' echo: ' + '%d' % msg)

    thread_0 = threading.Thread(target=producer_0)
    thread_1 = threading.Thread(target=producer_0_delay)
    thread_2 = threading.Thread(target=producer_1)
    thread_3 = threading.Thread(target=worker_watch_delayed, args=(conn,))
    thread_4 = threading.Thread(target=worker_watch_queue, args=(conn, 'echo', callback))

    thread_0.start()
    thread_1.start()
    thread_2.start()
    thread_3.start()
    thread_4.start()

    thread_0.join()
    thread_1.join()
    thread_2.join()
    thread_3.join()
    thread_4.join()
```
输出如下:
```code
producer_0 echo: 1
producer_1 echo: 1
producer_1 echo: 2
producer_1 echo: 3
producer_1 echo: 4
producer_0 echo: 2
acquire_lock...
release_lock...
producer_0_delay echo: 1
producer_1 echo: 5
producer_1 echo: 6
producer_1 echo: 7
acquire_lock...
producer_0_delay echo: 2
release_lock...
producer_1 echo: 8
producer_0 echo: 3
producer_1 echo: 9
acquire_lock...
producer_0_delay echo: 3
release_lock...
producer_1 echo: 10
producer_1 echo: 11
acquire_lock...
producer_0_delay echo: 4
release_lock...
producer_1 echo: 12
producer_0 echo: 4
producer_1 echo: 13
acquire_lock...
producer_0_delay echo: 5
release_lock...
producer_1 echo: 14
producer_1 echo: 15
acquire_lock...
producer_0_delay echo: 6
release_lock...
producer_1 echo: 16
```

## 散列

`Redis`的散列可以存储多个键值对之间的映射. 和字符串一样, 散列存储的值即可以是字节串, 也可以是整数值, 并且用户可以使用`HINCR`和`HDECR`对整数值执行自增或自减操作.

散列除了作为普通的键值映射外, 还可以将散列键看作文档数据库中的"文档".

## 压缩列表

压缩列表是列表键,哈希键以及有序集合的底层实现之一.

当一个列表键只包含少量列表项, 并且每个列表项要么就是小整数值, 要么就是长度比较短的字符串, 那么`Redis`就会使用压缩列表来做列表键的底层实现.

每个压缩列表的节点都包括三个部分:

- `previous_entry_length`: 上一个节点的长度;
- `encoding`: 包括节点保存的数据类型(字节数组/整数值)以及当前节点的长度;
- `content`: 被存储的字符串值;

压缩列表是一种为节约内存而开发的顺序型数据结构. 添加新节点到压缩列表， 或者从压缩列表中删除节点， 由于`previous_entry_length`属性占据的字节数会发生变化, 可能会引发连锁更新操作, 但这种操作出现的几率并不高.

在`Redis`配置选项中, 能够配置列表, 散列和有序集合什么时候使用压缩列表节省内存:

```ini
list-max-ziplist-entries 512
list-max-ziplist-value 64

hash-max-ziplist-entries 512
hash-max-ziplist-value 64

zset-max-ziplist-entries 128
zset-max-ziplist-value 64
```

`entries`选项表示编码为压缩列表时, 最多能包含的元素数量; `value`选项说明了压缩列表每个节点的最大体积是多少字节. 当突破这些限制时, `Redis`将压缩列表会转码成正常的数据结构.

## 整数集合

整数集合（intset）是 Redis 用于保存整数值的集合抽象数据结构, 支持`int16_t`、`int32_t`或者`int64_t`类型, 整数集合会根据添加的元素类型, 进行"升级"操作.

整数集合不光能节省内存, 还可以提升所有标准集合操作的执行速度. 下面是定义整数集合最大元素数量的配置选项:

```ini
set-max-ziplist-entries 512
```

## References

`>>> ` [Redis设计与实现](http://redisbook.com/)<br>
`>>> ` [Redis命令参考](http://redisdoc.com/)<br>
`>>> ` [基于Redis的分布式锁到底安全吗?](http://zhangtielei.com/posts/blog-redlock-reasoning.html)<br>